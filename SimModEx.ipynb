{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statemets\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from customScripts import utilities as util\n",
    "from customScripts import features as feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "#number of samples / second\n",
    "sampling_rate = 48000\n",
    "\n",
    "#length of frame in samples\n",
    "frame_length = 48000\n",
    "\n",
    "#number of samples used as offset for earch consecutive frame\n",
    "hop_length = 24000\n",
    "\n",
    "#number of mel frequency bins to use\n",
    "bin_number = 40 # also try 80\n",
    "\n",
    "#set the desired number of frames / second here\n",
    "ground_thruth_conversion_const = 2\n",
    "\n",
    "#input data\n",
    "file_paths = ['audio_files/Muppets-02-01-01.wav', 'audio_files/Muppets-02-04-04.wav', 'audio_files/Muppets-03-04-03.wav']\n",
    "grount_truth_paths = ['ground_truth/Muppets-02-01-01.csv', 'ground_truth/Muppets-02-04-04.csv', 'ground_truth/Muppets-03-04-03.csv']\n",
    "prediction_paths = ['predictions/Muppets-02-01-01.csv', 'predictions/Muppets-02-04-04.csv', 'predictions/Muppets-03-04-03.csv']\n",
    "file_lengths = [1547, 1548, 1539] #in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File loading and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load episode 1\n",
    "y_1 = util.load_audio(file_paths[0], sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load episode 2\n",
    "y_2 = util.load_audio(file_paths[1], sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load episode 3\n",
    "y_3 = util.load_audio(file_paths[2], sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute spectrogram for episode 1\n",
    "spectrogram_1 = feat.compute_spectrogram(y_1, frame_length, hop_length, bin_number)\n",
    "spectrogram_1T = spectrogram_1.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute spectrogram for episode 2\n",
    "spectrogram_2 = feat.compute_spectrogram(y_2, frame_length, hop_length, bin_number)\n",
    "spectrogram_2T = spectrogram_2.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute spectrogram for episode 3\n",
    "spectrogram_3 = feat.compute_spectrogram(y_3, frame_length, hop_length, bin_number)\n",
    "spectrogram_3T = spectrogram_3.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ground truth, pad it with zeroes and adjust to frame number\n",
    "\n",
    "#episode 1\n",
    "gt_1 = util.load_ground_truth(grount_truth_paths[0], '/n')\n",
    "gt_1 = util.compute_0_padded_gt(gt_1, file_lengths[0])\n",
    "gt_1 = util.adjust_gt_to_frames(gt_1, ground_thruth_conversion_const)\n",
    "gt_1.append(0) # append a zero so that lenght equals the frames list length\n",
    "\n",
    "#episode 2\n",
    "gt_2 = util.load_ground_truth(grount_truth_paths[1], '/n')\n",
    "gt_2 = util.compute_0_padded_gt(gt_2, file_lengths[1])\n",
    "gt_2 = util.adjust_gt_to_frames(gt_2, ground_thruth_conversion_const)\n",
    "gt_2.append(0) # append a zero so that lenght equals the frames list length\n",
    "\n",
    "#episode 3\n",
    "gt_3 = util.load_ground_truth(grount_truth_paths[2], '/n')\n",
    "gt_3 = util.compute_0_padded_gt(gt_3, file_lengths[2])\n",
    "gt_3 = util.adjust_gt_to_frames(gt_3, ground_thruth_conversion_const)\n",
    "gt_3.append(0) # append a zero so that lenght equals the frames list length\n",
    "gt_3.append(0) # append a zero so that lenght equals the frames list length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate training data\n",
    "\n",
    "gt_train = gt_1 + gt_2\n",
    "\n",
    "spectrogram_train = np.concatenate((spectrogram_1T, spectrogram_2T), axis=0)\n",
    "\n",
    "spectrogram_predict = spectrogram_3T\n",
    "\n",
    "#spectrogram_train[3195] == spectrogram_2T[100]\n",
    "\n",
    "#for i,g in enumerate(gt_train):\n",
    "#    if g == 1:\n",
    "#        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(spectrogram_train, gt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(spectrogram_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(prediction_paths[2], prediction, delimiter=\"/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
